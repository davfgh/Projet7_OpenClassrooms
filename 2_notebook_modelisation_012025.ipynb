{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import notebook\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from lightgbm import LGBMClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "packages = {\n",
    "    \"Python\": sys,\n",
    "    \"Jupyter Notebook\": \"notebook\",\n",
    "    \"NumPy\": \"numpy\",\n",
    "    \"Pandas\": \"pandas\",\n",
    "    \"Matplotlib\": \"matplotlib\",\n",
    "    \"Seaborn\": \"seaborn\",\n",
    "    \"MLflow\" : \"mlflow\",\n",
    "    \"Scikit-Learn\": \"sklearn\",\n",
    "    \"LightGMB\": \"lightgbm\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version de Python : 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 17:28:07) [MSC v.1916 64 bit (AMD64)]\n",
      "Version de Jupyter Notebook : 7.0.8\n",
      "Version de NumPy : 1.26.4\n",
      "Version de Pandas : 2.2.3\n",
      "Version de Matplotlib : 3.9.2\n",
      "Version de Seaborn : 0.13.2\n",
      "Version de MLflow : 2.19.0\n",
      "Version de Scikit-Learn : 1.5.1\n",
      "Version de LightGMB : 4.3.0\n"
     ]
    }
   ],
   "source": [
    "errorMsg = (\n",
    "    \"non disponible - vérifiez que le package existe, qu'il est correctement installé, importé \"\n",
    "    \"et qu'il dispose d'un attribut '__version__'.\"\n",
    ")\n",
    "for name, module in packages.items():\n",
    "    if isinstance(module, str):\n",
    "        version = getattr(sys.modules.get(module, None), '__version__', errorMsg)\n",
    "    else:\n",
    "        if module is sys:\n",
    "            version = sys.version\n",
    "        else:\n",
    "            version = getattr(module, '__version__', errorMsg)\n",
    "\n",
    "    print(f\"Version de {name} : {version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation de l'environement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Donnée fictives pour tester le fonctionnement de l'environement\n",
    "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 362, number of negative: 388\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000540 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2502\n",
      "[LightGBM] [Info] Number of data points in the train set: 750, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.482667 -> initscore=-0.069361\n",
      "[LightGBM] [Info] Start training from score -0.069361\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/10 16:37:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")  # Stockage local MLflow\n",
    "\n",
    "with mlflow.start_run(run_name=\"LightGBM_baseline\"):\n",
    "    # 1. Logging de paramètres basiques\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "\n",
    "    # 2. Entraînement de LightGBM (sans hyperparamètres particuliers)\n",
    "    model = LGBMClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 3. Évaluation\n",
    "    auc_score = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "    mlflow.log_metric(\"AUC\", auc_score)\n",
    "\n",
    "    # 4. Enregistrement du modèle\n",
    "    mlflow.sklearn.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Activer l'environement :\n",
    "conda activate D:/Pro/Env\n",
    "\n",
    "Lancer l'UI MLflow :\n",
    "mlflow ui --backend-store-uri sqlite:///mlruns.db\n",
    "\n",
    "Accéder au serveur dans le navigateur :\n",
    "http://127.0.0.1:5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ouvrir le dossier\n",
    "# cd /D D:\\Pro\\OpenClassrooms\\Projet_7\\3_dossier_code_012025\n",
    "# Remote\n",
    "# git remote -v\n",
    "# git push -u origin main\n",
    "# davfgh\n",
    "# token à la place du password git\n",
    "\n",
    "# Test unitaire\n",
    "# pytest tests/\n",
    "# Vérifier dans quel notebook ou script se font les test\n",
    "# écrire le code qui permet juste de vérifier que cela marche\n",
    "# Faire les installations\n",
    "# Créée le dossier\n",
    "\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
