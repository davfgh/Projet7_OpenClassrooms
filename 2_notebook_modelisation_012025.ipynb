{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import notebook\n",
    "import re\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "packages = {\n",
    "    \"Python\": sys,\n",
    "    \"Jupyter Notebook\": \"notebook\",\n",
    "    \"NumPy\": \"numpy\",\n",
    "    \"Pandas\": \"pandas\",\n",
    "    \"Matplotlib\": \"matplotlib\",\n",
    "    \"Seaborn\": \"seaborn\",\n",
    "    \"MLflow\" : \"mlflow\",\n",
    "    \"Scikit-Learn\": \"sklearn\",\n",
    "    \"LightGMB\": \"lightgbm\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version de Python : 3.12.8 (tags/v3.12.8:2dc476b, Dec  3 2024, 19:30:04) [MSC v.1942 64 bit (AMD64)]\n",
      "Version de Jupyter Notebook : 7.3.2\n",
      "Version de NumPy : 2.2.2\n",
      "Version de Pandas : 2.2.3\n",
      "Version de Matplotlib : 3.10.0\n",
      "Version de Seaborn : 0.13.2\n",
      "Version de MLflow : 2.19.0\n",
      "Version de Scikit-Learn : 1.6.1\n",
      "Version de LightGMB : 4.5.0\n"
     ]
    }
   ],
   "source": [
    "errorMsg = (\n",
    "    \"non disponible - vérifiez que le package existe, qu'il est correctement installé, importé \"\n",
    "    \"et qu'il dispose d'un attribut '__version__'.\"\n",
    ")\n",
    "for name, module in packages.items():\n",
    "    if isinstance(module, str):\n",
    "        version = getattr(sys.modules.get(module, None), '__version__', errorMsg)\n",
    "    else:\n",
    "        if module is sys:\n",
    "            version = sys.version\n",
    "        else:\n",
    "            version = getattr(module, '__version__', errorMsg)\n",
    "\n",
    "    print(f\"Version de {name} : {version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tentative de lecture avec l'encodage : utf-8\n",
      "application_test chargé avec succès !\n",
      "\n",
      "Tentative de lecture avec l'encodage : utf-8\n",
      "application_train chargé avec succès !\n",
      "\n",
      "Tentative de lecture avec l'encodage : utf-8\n",
      "bureau chargé avec succès !\n",
      "\n",
      "Tentative de lecture avec l'encodage : utf-8\n",
      "bureau_balance chargé avec succès !\n",
      "\n",
      "Tentative de lecture avec l'encodage : utf-8\n",
      "credit_card_balance chargé avec succès !\n",
      "\n",
      "Tentative de lecture avec l'encodage : utf-8\n",
      "Erreur avec l'encodage : utf-8\n",
      "Tentative de lecture avec l'encodage : latin1\n",
      "homecredit_columns_description chargé avec succès !\n",
      "\n",
      "Tentative de lecture avec l'encodage : utf-8\n",
      "installments_payments chargé avec succès !\n",
      "\n",
      "Tentative de lecture avec l'encodage : utf-8\n",
      "pos_cash_balance chargé avec succès !\n",
      "\n",
      "Tentative de lecture avec l'encodage : utf-8\n",
      "previous_application chargé avec succès !\n",
      "\n",
      "Application_test Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48744 entries, 0 to 48743\n",
      "Columns: 121 entries, SK_ID_CURR to AMT_REQ_CREDIT_BUREAU_YEAR\n",
      "dtypes: float64(65), int64(40), object(16)\n",
      "memory usage: 45.0+ MB\n",
      "None \n",
      "\n",
      "Application_train Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 307511 entries, 0 to 307510\n",
      "Columns: 122 entries, SK_ID_CURR to AMT_REQ_CREDIT_BUREAU_YEAR\n",
      "dtypes: float64(65), int64(41), object(16)\n",
      "memory usage: 286.2+ MB\n",
      "None \n",
      "\n",
      "Bureau Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1716428 entries, 0 to 1716427\n",
      "Data columns (total 17 columns):\n",
      " #   Column                  Dtype  \n",
      "---  ------                  -----  \n",
      " 0   SK_ID_CURR              int64  \n",
      " 1   SK_ID_BUREAU            int64  \n",
      " 2   CREDIT_ACTIVE           object \n",
      " 3   CREDIT_CURRENCY         object \n",
      " 4   DAYS_CREDIT             int64  \n",
      " 5   CREDIT_DAY_OVERDUE      int64  \n",
      " 6   DAYS_CREDIT_ENDDATE     float64\n",
      " 7   DAYS_ENDDATE_FACT       float64\n",
      " 8   AMT_CREDIT_MAX_OVERDUE  float64\n",
      " 9   CNT_CREDIT_PROLONG      int64  \n",
      " 10  AMT_CREDIT_SUM          float64\n",
      " 11  AMT_CREDIT_SUM_DEBT     float64\n",
      " 12  AMT_CREDIT_SUM_LIMIT    float64\n",
      " 13  AMT_CREDIT_SUM_OVERDUE  float64\n",
      " 14  CREDIT_TYPE             object \n",
      " 15  DAYS_CREDIT_UPDATE      int64  \n",
      " 16  AMT_ANNUITY             float64\n",
      "dtypes: float64(8), int64(6), object(3)\n",
      "memory usage: 222.6+ MB\n",
      "None \n",
      "\n",
      "Bureau_balance Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27299925 entries, 0 to 27299924\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Dtype \n",
      "---  ------          ----- \n",
      " 0   SK_ID_BUREAU    int64 \n",
      " 1   MONTHS_BALANCE  int64 \n",
      " 2   STATUS          object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 624.8+ MB\n",
      "None \n",
      "\n",
      "Credit_card_balance Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3840312 entries, 0 to 3840311\n",
      "Data columns (total 23 columns):\n",
      " #   Column                      Dtype  \n",
      "---  ------                      -----  \n",
      " 0   SK_ID_PREV                  int64  \n",
      " 1   SK_ID_CURR                  int64  \n",
      " 2   MONTHS_BALANCE              int64  \n",
      " 3   AMT_BALANCE                 float64\n",
      " 4   AMT_CREDIT_LIMIT_ACTUAL     int64  \n",
      " 5   AMT_DRAWINGS_ATM_CURRENT    float64\n",
      " 6   AMT_DRAWINGS_CURRENT        float64\n",
      " 7   AMT_DRAWINGS_OTHER_CURRENT  float64\n",
      " 8   AMT_DRAWINGS_POS_CURRENT    float64\n",
      " 9   AMT_INST_MIN_REGULARITY     float64\n",
      " 10  AMT_PAYMENT_CURRENT         float64\n",
      " 11  AMT_PAYMENT_TOTAL_CURRENT   float64\n",
      " 12  AMT_RECEIVABLE_PRINCIPAL    float64\n",
      " 13  AMT_RECIVABLE               float64\n",
      " 14  AMT_TOTAL_RECEIVABLE        float64\n",
      " 15  CNT_DRAWINGS_ATM_CURRENT    float64\n",
      " 16  CNT_DRAWINGS_CURRENT        int64  \n",
      " 17  CNT_DRAWINGS_OTHER_CURRENT  float64\n",
      " 18  CNT_DRAWINGS_POS_CURRENT    float64\n",
      " 19  CNT_INSTALMENT_MATURE_CUM   float64\n",
      " 20  NAME_CONTRACT_STATUS        object \n",
      " 21  SK_DPD                      int64  \n",
      " 22  SK_DPD_DEF                  int64  \n",
      "dtypes: float64(15), int64(7), object(1)\n",
      "memory usage: 673.9+ MB\n",
      "None \n",
      "\n",
      "Homecredit_columns_description Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 219 entries, 0 to 218\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Unnamed: 0   219 non-null    int64 \n",
      " 1   Table        219 non-null    object\n",
      " 2   Row          219 non-null    object\n",
      " 3   Description  219 non-null    object\n",
      " 4   Special      86 non-null     object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 8.7+ KB\n",
      "None \n",
      "\n",
      "Installments_payments Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13605401 entries, 0 to 13605400\n",
      "Data columns (total 8 columns):\n",
      " #   Column                  Dtype  \n",
      "---  ------                  -----  \n",
      " 0   SK_ID_PREV              int64  \n",
      " 1   SK_ID_CURR              int64  \n",
      " 2   NUM_INSTALMENT_VERSION  float64\n",
      " 3   NUM_INSTALMENT_NUMBER   int64  \n",
      " 4   DAYS_INSTALMENT         float64\n",
      " 5   DAYS_ENTRY_PAYMENT      float64\n",
      " 6   AMT_INSTALMENT          float64\n",
      " 7   AMT_PAYMENT             float64\n",
      "dtypes: float64(5), int64(3)\n",
      "memory usage: 830.4 MB\n",
      "None \n",
      "\n",
      "Pos_cash_balance Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10001358 entries, 0 to 10001357\n",
      "Data columns (total 8 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   SK_ID_PREV             int64  \n",
      " 1   SK_ID_CURR             int64  \n",
      " 2   MONTHS_BALANCE         int64  \n",
      " 3   CNT_INSTALMENT         float64\n",
      " 4   CNT_INSTALMENT_FUTURE  float64\n",
      " 5   NAME_CONTRACT_STATUS   object \n",
      " 6   SK_DPD                 int64  \n",
      " 7   SK_DPD_DEF             int64  \n",
      "dtypes: float64(2), int64(5), object(1)\n",
      "memory usage: 610.4+ MB\n",
      "None \n",
      "\n",
      "Previous_application Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1670214 entries, 0 to 1670213\n",
      "Data columns (total 37 columns):\n",
      " #   Column                       Non-Null Count    Dtype  \n",
      "---  ------                       --------------    -----  \n",
      " 0   SK_ID_PREV                   1670214 non-null  int64  \n",
      " 1   SK_ID_CURR                   1670214 non-null  int64  \n",
      " 2   NAME_CONTRACT_TYPE           1670214 non-null  object \n",
      " 3   AMT_ANNUITY                  1297979 non-null  float64\n",
      " 4   AMT_APPLICATION              1670214 non-null  float64\n",
      " 5   AMT_CREDIT                   1670213 non-null  float64\n",
      " 6   AMT_DOWN_PAYMENT             774370 non-null   float64\n",
      " 7   AMT_GOODS_PRICE              1284699 non-null  float64\n",
      " 8   WEEKDAY_APPR_PROCESS_START   1670214 non-null  object \n",
      " 9   HOUR_APPR_PROCESS_START      1670214 non-null  int64  \n",
      " 10  FLAG_LAST_APPL_PER_CONTRACT  1670214 non-null  object \n",
      " 11  NFLAG_LAST_APPL_IN_DAY       1670214 non-null  int64  \n",
      " 12  RATE_DOWN_PAYMENT            774370 non-null   float64\n",
      " 13  RATE_INTEREST_PRIMARY        5951 non-null     float64\n",
      " 14  RATE_INTEREST_PRIVILEGED     5951 non-null     float64\n",
      " 15  NAME_CASH_LOAN_PURPOSE       1670214 non-null  object \n",
      " 16  NAME_CONTRACT_STATUS         1670214 non-null  object \n",
      " 17  DAYS_DECISION                1670214 non-null  int64  \n",
      " 18  NAME_PAYMENT_TYPE            1670214 non-null  object \n",
      " 19  CODE_REJECT_REASON           1670214 non-null  object \n",
      " 20  NAME_TYPE_SUITE              849809 non-null   object \n",
      " 21  NAME_CLIENT_TYPE             1670214 non-null  object \n",
      " 22  NAME_GOODS_CATEGORY          1670214 non-null  object \n",
      " 23  NAME_PORTFOLIO               1670214 non-null  object \n",
      " 24  NAME_PRODUCT_TYPE            1670214 non-null  object \n",
      " 25  CHANNEL_TYPE                 1670214 non-null  object \n",
      " 26  SELLERPLACE_AREA             1670214 non-null  int64  \n",
      " 27  NAME_SELLER_INDUSTRY         1670214 non-null  object \n",
      " 28  CNT_PAYMENT                  1297984 non-null  float64\n",
      " 29  NAME_YIELD_GROUP             1670214 non-null  object \n",
      " 30  PRODUCT_COMBINATION          1669868 non-null  object \n",
      " 31  DAYS_FIRST_DRAWING           997149 non-null   float64\n",
      " 32  DAYS_FIRST_DUE               997149 non-null   float64\n",
      " 33  DAYS_LAST_DUE_1ST_VERSION    997149 non-null   float64\n",
      " 34  DAYS_LAST_DUE                997149 non-null   float64\n",
      " 35  DAYS_TERMINATION             997149 non-null   float64\n",
      " 36  NFLAG_INSURED_ON_APPROVAL    997149 non-null   float64\n",
      "dtypes: float64(15), int64(6), object(16)\n",
      "memory usage: 471.5+ MB\n",
      "None \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def read_csv_with_fallback(filepath, encodings=['utf-8', 'latin1', 'ISO-8859-1', 'cp1252']):\n",
    "    \"\"\"\n",
    "    Lecture d'un fichier CSV avec tentative sur plusieurs encodages.\n",
    "\n",
    "    Parameters:\n",
    "    - filepath (str): Chemin du fichier à lire.\n",
    "    - encodings (list): Liste des encodages à tester.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Le DataFrame pandas chargé.\n",
    "\n",
    "    Raises:\n",
    "    - UnicodeDecodeError: Si aucun des encodages ne fonctionne.\n",
    "    \"\"\"\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            print(f\"Tentative de lecture avec l'encodage : {encoding}\")\n",
    "            return pd.read_csv(filepath, encoding=encoding)\n",
    "        except UnicodeDecodeError:\n",
    "            print(f\"Erreur avec l'encodage : {encoding}\")\n",
    "\n",
    "    raise UnicodeDecodeError(f\"Impossible de lire le fichier {filepath} avec les encodages {encodings}\")\n",
    "\n",
    "# Chemin vers le nouveau dossier \"data\"\n",
    "data_path = \"D://Pro//OpenClassrooms//Projet_7//data//\"\n",
    "\n",
    "# Liste des fichiers et noms de DataFrame correspondants\n",
    "files = {\n",
    "    \"application_test\": \"application_test.csv\",\n",
    "    \"application_train\": \"application_train.csv\",\n",
    "    \"bureau\": \"bureau.csv\",\n",
    "    \"bureau_balance\": \"bureau_balance.csv\",\n",
    "    \"credit_card_balance\": \"credit_card_balance.csv\",\n",
    "    \"homecredit_columns_description\": \"HomeCredit_columns_description.csv\",\n",
    "    \"installments_payments\": \"installments_payments.csv\",\n",
    "    \"pos_cash_balance\": \"POS_CASH_balance.csv\",\n",
    "    \"previous_application\": \"previous_application.csv\"\n",
    "}\n",
    "\n",
    "# Chargement des fichiers dans des DataFrames\n",
    "loaded_data = {}\n",
    "for name, file in files.items():\n",
    "    filepath = data_path + file\n",
    "    loaded_data[name] = read_csv_with_fallback(filepath)\n",
    "    print(f\"{name} chargé avec succès !\\n\")\n",
    "\n",
    "# Affichage des informations pour chaque DataFrame\n",
    "for name, df in loaded_data.items():\n",
    "    print(f\"{name.capitalize()} Info:\")\n",
    "    print(df.info(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation de l'environement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Données fictives pour le modèle Random Forest\n",
    "X, y = make_classification(n_samples=1000, n_features=10, random_state=123)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 'RandomForest_Model_Tracking' configured with tracking URI: sqlite:///mlruns.db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/24 12:32:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'RandomForest_Model' already exists. Creating a new version of this model...\n",
      "Created version '4' of model 'RandomForest_Model'.\n",
      "C:\\Users\\dfari\\AppData\\Local\\Temp\\ipykernel_24868\\1878171291.py:40: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  latest_version_rf = client.get_latest_versions(registered_model_name_rf, stages=[\"None\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest version of 'RandomForest_Model': 4\n",
      "Run 'a1c9690cf713419d9dd07ba6be75d6f0' completed and logged to experiment 'RandomForest_Experiment'.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")  # Stockage local MLflow\n",
    "\n",
    "# Expérimentation\n",
    "experiment_name = \"RandomForest_Model_Tracking\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "print(f\"Experiment '{experiment_name}' configured with tracking URI: sqlite:///mlruns.db\")\n",
    "\n",
    "# Lancement d'expérimentation pour Random Forest\n",
    "with mlflow.start_run(run_name=\"RandomForest_Baseline_Experiment\") as run:\n",
    "    # Tags de l’expérimentation\n",
    "    mlflow.set_tag(\"version_data\", \"v1.0\")\n",
    "    mlflow.set_tag(\"description\", \"Baseline Random Forest model\")\n",
    "\n",
    "    # 1. Logging des paramètres\n",
    "    mlflow.log_param(\"n_estimators\", 200)\n",
    "    mlflow.log_param(\"max_depth\", None)\n",
    "    mlflow.log_param(\"random_state\", 123)\n",
    "\n",
    "    # 2. Entraînement du modèle Random Forest\n",
    "    rf_model = RandomForestClassifier(n_estimators=200, random_state=123)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # 3. Évaluation\n",
    "    auc_score_rf = roc_auc_score(y_test, rf_model.predict_proba(X_test)[:, 1])\n",
    "    mlflow.log_metric(\"AUC\", auc_score_rf)\n",
    "\n",
    "    # 4. Enregistrement du modèle\n",
    "    registered_model_name_rf = \"RandomForest_Model\"\n",
    "    mlflow.sklearn.log_model(\n",
    "        rf_model,\n",
    "        \"model\",\n",
    "        registered_model_name=registered_model_name_rf\n",
    "    )\n",
    "\n",
    "    # Récupération et affichage de la dernière version enregistrée\n",
    "    client = MlflowClient()\n",
    "    latest_version_rf = client.get_latest_versions(registered_model_name_rf, stages=[\"None\"])\n",
    "    print(f\"Latest version of '{registered_model_name_rf}': {latest_version_rf[0].version}\")\n",
    "\n",
    "    print(f\"Run '{run.info.run_id}' completed and logged to experiment 'RandomForest_Experiment'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Donnée fictives pour le modèle LightGBM\n",
    "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 'LightGBM_Model_Tracking' configured with tracking URI: sqlite:///mlruns.db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Pro\\OpenClassrooms\\Projet_7\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 362, number of negative: 388\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000793 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2502\n",
      "[LightGBM] [Info] Number of data points in the train set: 750, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.482667 -> initscore=-0.069361\n",
      "[LightGBM] [Info] Start training from score -0.069361\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Pro\\OpenClassrooms\\Projet_7\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "2025/01/24 12:32:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'LightGBM_Model' already exists. Creating a new version of this model...\n",
      "Created version '5' of model 'LightGBM_Model'.\n",
      "C:\\Users\\dfari\\AppData\\Local\\Temp\\ipykernel_24868\\3350498219.py:37: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  latest_version_lgbm = client.get_latest_versions(registered_model_name_lgbm, stages=[\"None\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest version of 'LightGBM_Model': 5\n",
      "Run 'c4b62b1c110b4ab0aa49a319c0a25973' completed and logged to experiment 'LightGBM_Model_Tracking'.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")  # Stockage local MLflow\n",
    "\n",
    "# Expérimentation\n",
    "experiment_name = \"LightGBM_Model_Tracking\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "print(f\"Experiment '{experiment_name}' configured with tracking URI: sqlite:///mlruns.db\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"LightGBM_Baseline_Experiment\") as run:\n",
    "    # Tags pour l'expérimentation\n",
    "    mlflow.set_tag(\"version_data\", \"v1.0\")\n",
    "    mlflow.set_tag(\"description\", \"Baseline model with default LightGBM parameters\")\n",
    "\n",
    "    # 1. Logging de paramètres basiques\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "\n",
    "    # 2. Entraînement de LightGBM (sans hyperparamètres particuliers)\n",
    "    model = LGBMClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 3. Évaluation\n",
    "    auc_score = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "    mlflow.log_metric(\"AUC\", auc_score)\n",
    "\n",
    "    registered_model_name_lgbm = \"LightGBM_Model\"\n",
    "    mlflow.sklearn.log_model(\n",
    "        model,\n",
    "        \"model\",\n",
    "        registered_model_name=registered_model_name_lgbm\n",
    "    )\n",
    "\n",
    "    # Récupérer et affichage de la dernière version enregistrée\n",
    "    client = MlflowClient()\n",
    "    latest_version_lgbm = client.get_latest_versions(registered_model_name_lgbm, stages=[\"None\"])\n",
    "    print(f\"Latest version of '{registered_model_name_lgbm}': {latest_version_lgbm[0].version}\")\n",
    "\n",
    "    print(f\"Run '{run.info.run_id}' completed and logged to experiment '{experiment_name}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération du fichier requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier raw_requirements.txt généré à D://Pro//OpenClassrooms//Projet_7//3_dossier_code_012025/raw_requirements.txt\n",
      "Fichier requirements.txt nettoyé généré à D://Pro//OpenClassrooms//Projet_7//3_dossier_code_012025/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "# Chemin vers les requirements\n",
    "raw_requirements_file = \"D://Pro//OpenClassrooms//Projet_7//3_dossier_code_012025/raw_requirements.txt\"\n",
    "cleaned_requirements_file = \"D://Pro//OpenClassrooms//Projet_7//3_dossier_code_012025/requirements.txt\"\n",
    "\n",
    "# Chemin absolu de pip\n",
    "pip_path = \"D://Pro//OpenClassrooms//Projet_7//.venv//Scripts//pip.exe\"\n",
    "\n",
    "# Repo\n",
    "os.makedirs(os.path.dirname(raw_requirements_file), exist_ok=True)\n",
    "\n",
    "# Générer le fichier raw_requirements.txt\n",
    "try:\n",
    "    with open(raw_requirements_file, \"w\") as f:\n",
    "        result = subprocess.run([pip_path, \"freeze\"], stdout=f, text=True, check=True)\n",
    "    print(f\"Fichier raw_requirements.txt généré à {raw_requirements_file}\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Erreur lors de l'exécution de pip freeze : {e}\")\n",
    "    exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"Une erreur inattendue s'est produite : {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Nettoyage du fichier requirements\n",
    "try:\n",
    "    with open(raw_requirements_file, \"r\") as raw_f, open(cleaned_requirements_file, \"w\") as cleaned_f:\n",
    "        for line in raw_f:\n",
    "            # Nettoyage des lignes\n",
    "            if \"@ file://\" in line:\n",
    "                line = re.sub(r\"@ file://.*\", \"\", line)\n",
    "            cleaned_f.write(line)\n",
    "    print(f\"Fichier requirements.txt nettoyé généré à {cleaned_requirements_file}\")\n",
    "except Exception as e:\n",
    "    print(f\"Une erreur inattendue s'est produite lors du nettoyage : {e}\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Activer l'environement (avec .venv):\n",
    "cd 3_dossier_code_012025\n",
    "Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass\n",
    "D:\\Pro\\OpenClassrooms\\Projet_7\\.venv\\Scripts\\Activate.ps1\n",
    "\n",
    "# Activer l'environement (avec Anaconda):\n",
    "conda activate D:/Pro/Env\n",
    "\n",
    "# Lancer l'UI MLflow :\n",
    "mlflow ui --backend-store-uri sqlite:///mlruns.db\n",
    "\n",
    "# Accéder au serveur MLflow (dans le navigateur) :\n",
    "http://127.0.0.1:5000\n",
    "\n",
    "# Test unitaire avec PyTest\n",
    "pytest tests/\n",
    "\n",
    "# Pousser les modifications sur Git\n",
    "git add .\n",
    "git commit -m \"Modifications...\"\n",
    "# Sur branche de dévloppement\n",
    "git push origin ajout-tests-ci\n",
    "# Sur branche principale\n",
    "git push origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procédure d'installation sur nouvelle machine\n",
    "# cd /D D:\\Pro\\OpenClassrooms\\Projet_7\\3_dossier_code_012025\n",
    "# Remote\n",
    "# git remote -v\n",
    "# git remote add origin https://github.com/davfgh/Projet7_OpenClassrooms.git\n",
    "# git push -u origin main\n",
    "# davfgh\n",
    "# token à la place du password git"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
